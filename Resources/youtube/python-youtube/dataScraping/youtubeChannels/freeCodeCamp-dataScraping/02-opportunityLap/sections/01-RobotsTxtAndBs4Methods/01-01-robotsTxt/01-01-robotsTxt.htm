<h1>01-01 - robots.txt</h1>
<div class="steps-container show">
    <!-- 01-01 -->    
    <div class="step">
        <div tabindex="1" class="step-txt w-50">
            <h4>01</h4>
            <p>
                &emsp;Go to a website like <a target="_blank" href="https://twitter.com/">https://twitter.com/</a>
                or <a target="_blank" href="https://www.linkedin.com/">https://www.linkedin.com/</a> and add
                <strong><code>robots.txt</code></strong> to the end of the url to see what can and cannot be crawled or scraped
            </p>
            <div class="code-container">
                <pre tabindex="1" class="copy-code">
https://twitter.com/robots.txt</pre>
            </div>
            <p class="r">
                Nothing is allowed on linkedin
            </p>
            
        </div>
        <div class="step-img">
        <img class="lg-enlarge"
            src="/documentation/python/dataScraping/youtubeChannels/freeCodeCamp-dataScraping/02-opportunityLap/sections//01-RobotsTxtAndBs4Methods/images/01-02.png">
        </div>
    </div>
    <!-- 01-02 -->
    <div class="step">
        <div tabindex="1" class="step-txt">
            <h4>02</h4>
            <p>
                Ask chat gpt what is allowed to be scraped from <a target="_blank" href="https://www.nasdaq.com/">https://www.nasdaq.com/</a>
            </p>
            <div class="code-container">
                <pre tabindex="1" class="copy-code">
https://www.nasdaq.com/robots.txt</pre>
            </div>
            
        </div>
        <div class="step-img">
            <img class="xlg-enlarge" src="/documentation/python/dataScraping/youtubeChannels/freeCodeCamp-dataScraping/02-opportunityLap/sections/01-RobotsTxtAndBs4Methods/01-01-robotsTxt/images/01-02.png">
        </div>
    </div>
    <!-- 01-03    -->
    <div class="step">
        <div tabindex="1" class="step-txt">
            <h4>03</h4>
            <p>
                If you scoll to the bottom of <a target="_blank" href="https://www.linkedin.com/robots.txt#:~:text=agent%3A%20Cincobot%0AAllow%3A%20/*-,User%2Dagent%3A%20*,-Disallow%3A%20/%0A%0A%23%20Notice%3A%20If"
                >https://www.linkedin.com/robots.txt</a> you can see 
                <br>
                <code>
                    User-agent: *
                    <br>Disallow: /
                </code>
                <p>
                    the <code>*</code> means all users, and the <code>/</code> next to <code>Disallow</code> means everything within the page can <strong>NOT</strong>
                    be scraped or crawled
                </p>
            </p>
        </div>
        <div class="step-img">
            <img class="xlg-enlarge"
                src="/documentation/python/dataScraping/youtubeChannels/freeCodeCamp-dataScraping/02-opportunityLap/sections/01-RobotsTxtAndBs4Methods/01-01-robotsTxt/images/01-03.png">
        </div>
    </div>
    <!-- 01-04 -->
    <div class="step">
        <div tabindex="1" class="step-txt">
            <h4>04</h4>
            <p>
                <span class="lgtxt r">Remember</span>, this means 
                everything can be scraped
            </p>
        </div>
        <div class="step-img"> 
                <img class="xlg-enlarge" src="/documentation/python/dataScraping/youtubeChannels/freeCodeCamp-dataScraping/02-opportunityLap/sections/01-RobotsTxtAndBs4Methods/images/01-01.png">
        </div>
    </div>
</div>

