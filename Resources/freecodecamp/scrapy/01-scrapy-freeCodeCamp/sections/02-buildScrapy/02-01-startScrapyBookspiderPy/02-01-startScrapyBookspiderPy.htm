<h1>02-01-startScrapy (part 4 29:00mins)</h1>
<div class="steps-container show">
    <!-- 01-01 -->
    <div class="step">
        <div tabindex="0" class="step-txt">
            <h4>01</h4>
            <p>
                Make sure you are in the <code>spiders</code> directory
            </p>
            <div class="code-container">
                <pre tabindex="0" class="copy-code">
cd bookscraper/bookscraper/spiders
                </pre>
            </div>
        </div>
        <div class="step-img">
            <img src="sections/02-buildScrapy/02-01-startScrapyBookspiderPy/images/01.png">
        </div>
    </div>
    <!-- 01-02 -->
    <div class="step-col">
        <div tabindex="0" class="step-txt">
            <h4>02</h4>
            <p>
                Make a spider, in the spiders directory with the command,
            </p>
            <div class="code-container">
                <pre tabindex="0" class="copy-code">
scrapy <span class="m">genspider</span> <span class="o">bookspider</span> <span class="g">https://books.toscrape.com/</span>
                </pre>
            </div>
            <p>
                provide <span class="o">name</span> for spider alone with <code class="g">baseUrl</code>
            </p>
            <p> 
                This is the page the spider will base it self in
                <a target="_blank" class="g" href="https://books.toscrape.com/">https://books.toscrape.com/</a>
            </p>
        </div>
        <div class="img-container">
            <div class="step-img">
                <img src="sections/02-buildScrapy/02-01-startScrapyBookspiderPy/images/02.png">
            </div>
            <div class="step-img">
                <img
                    src="sections/02-buildScrapy/02-01-startScrapyBookspiderPy/images/01-02b.png">
            </div>
        </div>
    </div>
    <!-- 01-03 -->
    <div class="step">
        <div tabindex="0" class="step-txt">
            <h4>03</h4>
            <p>
                &emsp;The <code>allowed_domains</code> [] list will allow us to crawl, while limiting the amount of urls to connect to.
                This restricts the crawling to the allowed_domains websites only.
            </p>
            <p>
                &emsp;The <code>start_urls</code> is obviously the starting  urls.
            </p>
        </div>
        <div class="step-img">
            <img src="sections/02-buildScrapy/02-01-startScrapyBookspiderPy/images/01-03.png">
        </div>
    </div>
    <!-- 01-04 -->
    <div class="step">
        <div tabindex="0" class="step-txt">
            <h4>04</h4>
            <p>
                The <code class="m">response</code> in the <code class="gr">parse</code> method will be returned from the 
                <code>fetch</code> command seen in next lesson
            </p>
        </div>
        <div class="step-img">
            <img src="sections/02-buildScrapy/02-01-startScrapyBookspiderPy/images/01-04.png">
        </div>
    </div>
</div>
<footer>
    <button tabindex="0" id="nxtLesson">next lesson</button>
</footer>

